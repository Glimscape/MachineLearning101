{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding, strides的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hikaru\\Anaconda2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先定义一个X作为卷积层的输入，X为一个高宽为的(5,5)的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.5488135  0.5928446  0.71518934 0.84426576 0.60276335]\n",
       " [0.8579456  0.5448832  0.8472517  0.4236548  0.6235637 ]\n",
       " [0.6458941  0.3843817  0.4375872  0.2975346  0.891773  ]\n",
       " [0.05671298 0.96366274 0.2726563  0.3834415  0.47766513]\n",
       " [0.79172504 0.8121687  0.5288949  0.47997716 0.56804454]]\n",
       "<NDArray 5x5 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(5,5))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个X可以认为是只有一个通道且只有一个样本的数据，所以要先把它转换成卷积层能够运算的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[0.5488135  0.5928446  0.71518934 0.84426576 0.60276335]\n",
       "   [0.8579456  0.5448832  0.8472517  0.4236548  0.6235637 ]\n",
       "   [0.6458941  0.3843817  0.4375872  0.2975346  0.891773  ]\n",
       "   [0.05671298 0.96366274 0.2726563  0.3834415  0.47766513]\n",
       "   [0.79172504 0.8121687  0.5288949  0.47997716 0.56804454]]]]\n",
       "<NDArray 1x1x5x5 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape((1,1,) + X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个二维的卷积层，channels=1，kernel_size=3(卷积核高宽为3\\*3)，padding=0，strides=1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[-0.07265629 -0.02996709 -0.05599695]\n",
       "   [-0.08196221  0.0065964  -0.07164453]\n",
       "   [-0.05519189 -0.07947221 -0.03134103]]]]\n",
       "<NDArray 1x1x3x3 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2D(channels=1 , kernel_size=3, padding=0,strides=1)\n",
    "conv_layer.initialize(force_reinit=True)\n",
    "conv_layer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层的输出的高宽就变为了3\\*3。计算的方式为5-3+1=3\n",
    "\n",
    "当 kernel_size、padding、strides的值为(a,a)的形式时可以简写为a。在这里默认padding时候是对称地在两端各加入a行或者a列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv0_ (\n",
       "  Parameter conv0_weight (shape=(1L, 1L, 3L, 3L), dtype=<type 'numpy.float32'>)\n",
       "  Parameter conv0_bias (shape=(1L,), dtype=<type 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个卷积层一共有3\\*3+1=10个需要训练的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当channels=1，kernel_size=3，padding=1，strides=1时就会得到跟输入相同高宽的输出，因为 5 - 3 + 2 + 1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[0.07879697 0.13109213 0.10206491 0.12027679 0.01479829]\n",
       "   [0.14459844 0.18046197 0.18126246 0.18797696 0.10550467]\n",
       "   [0.16965365 0.12954047 0.19445038 0.1672945  0.1147798 ]\n",
       "   [0.14026433 0.20511073 0.115531   0.16248739 0.10643023]\n",
       "   [0.1242496  0.10454565 0.08863002 0.08350381 0.05368542]]]]\n",
       "<NDArray 1x1x5x5 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2D(channels=1 , kernel_size=3, padding=1,strides=1)\n",
    "conv_layer.initialize(force_reinit=True)\n",
    "conv_layer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当channels=1，kernel_size=3，padding=1，strides=2时："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[ 0.00512447  0.03436728  0.0735539 ]\n",
       "   [ 0.00474501  0.06926426  0.06970382]\n",
       "   [-0.02111948  0.05971721  0.04665373]]]]\n",
       "<NDArray 1x1x3x3 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2D(channels=1 , kernel_size=3, padding=1,strides=2)\n",
    "conv_layer.initialize(force_reinit=True)\n",
    "conv_layer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算方式为(5 - 3 + 2 + 2)/2=3 。这样一来就减小了输入的高宽。我们一半用strides来成倍减少输出的高宽。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积核同样可以是高宽不等的矩阵，计算方式是类似的。\n",
    "\n",
    "假设输入还是X, 请根据形状计算公式计算下面卷积层的输出形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2D(None -> 1, kernel_size=(2, 1), stride=(2, 1), padding=(2, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2D(channels=1 , kernel_size=(2, 1), padding=(2,3),strides=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多通道输入和输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要设置输出通道数只需在channels处指定即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[-0.05216176 -0.04653428  0.02504515]\n",
       "   [-0.01279594 -0.02271961 -0.01073688]\n",
       "   [ 0.01790022 -0.01827742  0.00246948]]\n",
       "\n",
       "  [[-0.08731312 -0.11926781 -0.09274729]\n",
       "   [ 0.00151717 -0.07124412 -0.08364075]\n",
       "   [ 0.01050385 -0.04050701 -0.02398763]]]]\n",
       "<NDArray 1x2x3x3 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2D(channels=2 , kernel_size=3, padding=1,strides=2)\n",
    "conv_layer.initialize(force_reinit=True)\n",
    "conv_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[0.6176355  0.14967486 0.6120957  0.22232139 0.616934  ]\n",
       "   [0.38648897 0.94374806 0.9025985  0.6818203  0.44994998]\n",
       "   [0.3595079  0.61306345 0.43703195 0.9023486  0.6976312 ]\n",
       "   [0.09928035 0.06022547 0.96980906 0.6667667  0.65314   ]\n",
       "   [0.67063785 0.17090958 0.21038257 0.35815218 0.12892629]]\n",
       "\n",
       "  [[0.75068617 0.31542835 0.60783064 0.36371076 0.32504722]\n",
       "   [0.57019675 0.03842543 0.43860152 0.63427407 0.9883738 ]\n",
       "   [0.95894927 0.10204481 0.6527903  0.20887676 0.6350589 ]\n",
       "   [0.16130951 0.9952996  0.6531083  0.58185035 0.2532916 ]\n",
       "   [0.4143686  0.46631077 0.4746975  0.2444256  0.6235101 ]]]]\n",
       "<NDArray 1x2x5x5 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = nd.random.uniform(shape=(1,2,5,5))\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[ 0.00712641 -0.0040303   0.03668668]\n",
       "   [-0.08360508 -0.11144921 -0.00838126]\n",
       "   [-0.05730859 -0.05394671 -0.00496497]]]]\n",
       "<NDArray 1x1x3x3 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer = nn.Conv2D(channels=1 , kernel_size=3, padding=1,strides=2)\n",
    "conv_layer.initialize(force_reinit=True)\n",
    "conv_layer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来搭建一个真正的深度卷积神经网络吧！\n",
    "\n",
    "这里我们使用了一个公开的的数据集 CIFAR-10。为了计算速度，我只用了100个训练样本和一个测试样本。做计算机视觉类任务时，一般把训练集、验证集和测试集的数据放在不同的文件夹中方便读取。\n",
    "\n",
    "整理之后一般把一类的文件放在同一个文件夹下面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mxnet.gluon import nn\n",
    "import h5py\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet.gluon import data as gdata, loss as gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio):\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((int(idx), label) for idx, label in tokens))\n",
    "    labels = set(idx_label.values())\n",
    "    \n",
    "    n_train_valid = len(os.listdir(os.path.join(data_dir, train_dir)))\n",
    "    n_train = int(n_train_valid * (1 - valid_ratio))\n",
    "    assert 0 < n_train < n_train_valid\n",
    "    n_train_per_label = n_train // len(labels)\n",
    "    label_count = {}\n",
    "\n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "\n",
    "    # 整理训练和验证集。\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = int(train_file.split('.')[0])\n",
    "        label = idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_train_per_label:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "\n",
    "    # 整理测试集。\n",
    "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "label_file = \"trainLabels.csv\"\n",
    "train_dir = 'train_tiny'\n",
    "test_dir = 'test_tiny'\n",
    "input_dir = \"train_valid_test\"\n",
    "valid_ratio=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = gdata.vision.transforms.Compose([\n",
    "    # 将图片放大成高和宽各为 40 像素的正方形。\n",
    "    gdata.vision.transforms.Resize(40),\n",
    "    # 随机对高和宽各为 40 像素的正方形图片裁剪出面积为原图片面积 0.64 到 1 倍之间的小正方\n",
    "    # 形，再放缩为高和宽各为 32 像素的正方形。\n",
    "    gdata.vision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),\n",
    "                                              ratio=(1.0, 1.0)),\n",
    "    # 随机左右翻转图片。\n",
    "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
    "    # 将图片像素值按比例缩小到 0 和 1 之间，并将数据格式从“高 * 宽 * 通道”改为“通道 * 高 * 宽”。\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    # 对图片的每个通道做标准化。\n",
    "    gdata.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                      [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "# 测试时，无需对图像做标准化以外的增强数据处理。\n",
    "transform_test = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    gdata.vision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                      [0.2023, 0.1994, 0.2010])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = gluon.data.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
    "valid_ds = gluon.data.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
    "train_valid_ds = gluon.data.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'train_valid'),\n",
    "                                           flag=1)\n",
    "test_ds = gluon.data.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'test'), flag=1)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds.transform_first(transform_test), batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data = loader(train_valid_ds.transform_first(transform_train), batch_size, shuffle=True,\n",
    "                          last_batch='keep')\n",
    "test_data = loader(test_ds.transform_first(transform_test), batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet():\n",
    "    net = nn.Sequential()\n",
    "    net.add(\n",
    "        nn.Conv2D(96, kernel_size=5, padding=2, strides=2, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        nn.Conv2D(256, kernel_size=3, padding=2, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 使用比 LeNet 输出大数倍了全连接层。其使用丢弃层来控制复杂度。\n",
    "        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
    "        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
    "        # 输出层。我们这里使用 CIFAR-10，所以用 10，而不是论文中的 1000。\n",
    "        nn.Dense(10)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "num_epochs = 5\n",
    "ctx = mx.gpu()\n",
    "net = alexnet()\n",
    "net.initialize(force_reinit=True, ctx = ctx, init = init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd})\n",
    "    train_loss = []\n",
    "    if valid_data is not None:\n",
    "        test_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        _loss = 0.\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            _loss += nd.mean(loss).asscalar()\n",
    "        __loss = _loss/len(train_data)\n",
    "        train_loss.append(__loss)\n",
    "        \n",
    "        if valid_data is not None:  \n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch,__loss , valid_loss))\n",
    "            test_loss.append(valid_loss)\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, __loss))\n",
    "            \n",
    "        print('lr ' + str(trainer.learning_rate))\n",
    "        \n",
    "\n",
    "    plt.plot(train_loss, 'r')\n",
    "    if valid_data is not None: \n",
    "        plt.plot(test_loss, 'g')\n",
    "    plt.legend(['Train_Loss', 'Test_Loss'], loc=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hikaru\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: All children of this Sequential layer 'sequential0_' are HybridBlocks. Consider using HybridSequential for the best performance.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001\n",
      "lr 0.001\n",
      "lr 0.001\n",
      "lr 0.001\n",
      "lr 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x330c9f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "#ctx = mx.gpu()\n",
    "#net = alexnet()\n",
    "net.hybridize()\n",
    "\n",
    "train(net, train_data,valid_data, num_epochs, 0.001, 0.002, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
