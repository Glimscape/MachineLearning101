{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性模型及其实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "\n",
    "这部分我们使用波士顿房价数据集来说明。这个数据集包含波士顿各个区域的多个特征，比如犯罪率、一氧化氮浓度、户主的年龄信息等，综合这些信息来估计某处房子的售价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入所需的数据集和包\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载数据集\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 查看数据集相关信息\n",
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 选取前400个数据作为训练集，剩下的作为测试集\n",
    "X_train = X[:400, :]\n",
    "y_train = y[:400]\n",
    "X_test = X[400:,:]\n",
    "y_test = y[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的规模为 (400L, 13L)，测试集的规模为 (106L, 13L)\n"
     ]
    }
   ],
   "source": [
    "print \"训练集的规模为 %s，测试集的规模为 %s\" % (str(X_train.shape), str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.672599590855004 [-1.91246374e-01  4.42289967e-02  5.52207977e-02  1.71631351e+00\n",
      " -1.49957220e+01  4.88773025e+00  2.60921031e-03 -1.29480799e+00\n",
      "  4.84787214e-01 -1.54006673e-02 -8.08795026e-01 -1.29230427e-03\n",
      " -5.17953791e-01]\n"
     ]
    }
   ],
   "source": [
    "## 输出所有的参数\n",
    "print lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们就可以用它来做预测了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为是回归问题，所以我们用 mean square error (mse) 来检验拟合程度的好坏。具体来说就是用这个模型去算一下测试集的 X ，看看结果跟测试集的 y 的 mse 有多大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 38.1643\n"
     ]
    }
   ],
   "source": [
    "print 'mse = %.4f' % np.mean(np.square(y_pred - y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取 Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是 LinearRegression 这个函数并不提供可供选择特征的参数。因为有些特征跟我们最终的 y 关系不大，如果硬要把它加在线性模型里，反而会造成更大的误差。\n",
    "\n",
    "所以这里我们另外导入一个包来做这件事："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hikaru\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个包的设定跟 sklearn 略有不同。它预设的模型就是 $y = \\boldsymbol{w}^T\\boldsymbol{x}$ ，没有 intercept 的部分。所以我们这里要手动加上一个常数项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着用 sm.OLS 来做线性回归。OLS=Ordinary Least Square 普通最小二乘。注意这里调用函数的时候要把y放前面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_sm = sm.OLS(y_train, X_train_1)\n",
    "results = lm_sm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.86725996e+01 -1.91246374e-01  4.42289967e-02  5.52207977e-02\n",
      "  1.71631351e+00 -1.49957220e+01  4.88773025e+00  2.60921031e-03\n",
      " -1.29480799e+00  4.84787214e-01 -1.54006673e-02 -8.08795026e-01\n",
      " -1.29230427e-03 -5.17953791e-01]\n"
     ]
    }
   ],
   "source": [
    "print results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这里的 params 跟上面 (intercept, coef) 的数值是一样的。\n",
    "\n",
    "那么问题来了，要如何做简单的特征选取呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.725</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   81.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 May 2018</td> <th>  Prob (F-statistic):</th> <td>2.92e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:28:21</td>     <th>  Log-Likelihood:    </th> <td> -1188.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   2405.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   386</td>      <th>  BIC:               </th> <td>   2461.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   28.6726</td> <td>    6.152</td> <td>    4.661</td> <td> 0.000</td> <td>   16.578</td> <td>   40.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1912</td> <td>    0.054</td> <td>   -3.539</td> <td> 0.000</td> <td>   -0.297</td> <td>   -0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0442</td> <td>    0.014</td> <td>    3.134</td> <td> 0.002</td> <td>    0.016</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0552</td> <td>    0.066</td> <td>    0.843</td> <td> 0.400</td> <td>   -0.074</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.7163</td> <td>    0.891</td> <td>    1.926</td> <td> 0.055</td> <td>   -0.036</td> <td>    3.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -14.9957</td> <td>    4.558</td> <td>   -3.290</td> <td> 0.001</td> <td>  -23.957</td> <td>   -6.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    4.8877</td> <td>    0.485</td> <td>   10.079</td> <td> 0.000</td> <td>    3.934</td> <td>    5.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0026</td> <td>    0.014</td> <td>    0.182</td> <td> 0.856</td> <td>   -0.026</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.2948</td> <td>    0.212</td> <td>   -6.116</td> <td> 0.000</td> <td>   -1.711</td> <td>   -0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.4848</td> <td>    0.087</td> <td>    5.550</td> <td> 0.000</td> <td>    0.313</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0154</td> <td>    0.004</td> <td>   -3.463</td> <td> 0.001</td> <td>   -0.024</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.8088</td> <td>    0.140</td> <td>   -5.774</td> <td> 0.000</td> <td>   -1.084</td> <td>   -0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0013</td> <td>    0.007</td> <td>   -0.198</td> <td> 0.843</td> <td>   -0.014</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.5180</td> <td>    0.060</td> <td>   -8.704</td> <td> 0.000</td> <td>   -0.635</td> <td>   -0.401</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>116.345</td> <th>  Durbin-Watson:     </th> <td>   1.124</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 538.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.177</td>  <th>  Prob(JB):          </th> <td>9.36e-118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.176</td>  <th>  Cond. No.          </th> <td>1.52e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.734\n",
       "Model:                            OLS   Adj. R-squared:                  0.725\n",
       "Method:                 Least Squares   F-statistic:                     81.87\n",
       "Date:                Fri, 04 May 2018   Prob (F-statistic):          2.92e-102\n",
       "Time:                        15:28:21   Log-Likelihood:                -1188.5\n",
       "No. Observations:                 400   AIC:                             2405.\n",
       "Df Residuals:                     386   BIC:                             2461.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         28.6726      6.152      4.661      0.000      16.578      40.768\n",
       "x1            -0.1912      0.054     -3.539      0.000      -0.297      -0.085\n",
       "x2             0.0442      0.014      3.134      0.002       0.016       0.072\n",
       "x3             0.0552      0.066      0.843      0.400      -0.074       0.184\n",
       "x4             1.7163      0.891      1.926      0.055      -0.036       3.468\n",
       "x5           -14.9957      4.558     -3.290      0.001     -23.957      -6.035\n",
       "x6             4.8877      0.485     10.079      0.000       3.934       5.841\n",
       "x7             0.0026      0.014      0.182      0.856      -0.026       0.031\n",
       "x8            -1.2948      0.212     -6.116      0.000      -1.711      -0.879\n",
       "x9             0.4848      0.087      5.550      0.000       0.313       0.657\n",
       "x10           -0.0154      0.004     -3.463      0.001      -0.024      -0.007\n",
       "x11           -0.8088      0.140     -5.774      0.000      -1.084      -0.533\n",
       "x12           -0.0013      0.007     -0.198      0.843      -0.014       0.012\n",
       "x13           -0.5180      0.060     -8.704      0.000      -0.635      -0.401\n",
       "==============================================================================\n",
       "Omnibus:                      116.345   Durbin-Watson:                   1.124\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              538.938\n",
       "Skew:                           1.177   Prob(JB):                    9.36e-118\n",
       "Kurtosis:                       8.176   Cond. No.                     1.52e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.52e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个 summary 结果我们首先关心的是右上角的 R-squared （决定系数）。一般来说这个值是正的。假如它的值变成了负数，说明当前模型非常不适合这个数据集，需要更换别的模型。\n",
    "\n",
    "第二张表的 coef 列就是前面的 params 。同一张表我们还需要关心的是 P>|t| 那一列。假如这里的数值大于0.05就可以考虑把相应的特征踢掉了。在里就是x3, x7, x12，对应变量名为:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INDUS' 'AGE' 'B']\n"
     ]
    }
   ],
   "source": [
    "print boston.feature_names[np.array([2,6,11])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INDUS 和 AGE 都比较好理解，B 出现在这里以我们对美国的了解肯定是不科学的。这里很有可能跟数据集的样本分布有关。因为我们划分训练集的时候是粗暴地取了前400个，而不是随机地抽取400个样本。\n",
    "\n",
    "请根据这个结论重新划分训练集/数据集进行分析，再根据结果做适当的特征筛选，观察筛选的结果是否降低了错误率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分我们用股票数据集 Smarket 来说明，数据放在Smarket.csv中。把它放在跟这个notebook同一个文件夹下即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们导入了另一个包 pandas，这也是一个 Python 数据分析里常用的包。用它可以一次性读入一个 csv 文件。它的功能非常强大。后面要用到的话再慢慢说。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket = pd.read_csv('Smarket.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 用shape函数查看数据集规模\n",
    "smarket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Year', u'Lag1', u'Lag2', u'Lag3', u'Lag4', u'Lag5', u'Volume',\n",
       "       u'Today', u'Direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看各个 column (feature) 的名称\n",
    "smarket.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集包含2001年到2005年间1250天 S&P 500 股票指数的投资回报数据。Year 表示年份，Lag1~Lag5表示过去1到5个交易日的投资回报率。Today是今日的投资回报率。Direction是市场走势，它有两类，Up和Down。另外还有一个特征是Volumn，表示前一日的成交量，单位是billion。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2003.016000</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>1.478305</td>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409018</td>\n",
       "      <td>1.136299</td>\n",
       "      <td>1.136280</td>\n",
       "      <td>1.138703</td>\n",
       "      <td>1.138774</td>\n",
       "      <td>1.14755</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>1.136334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2001.000000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.92200</td>\n",
       "      <td>0.356070</td>\n",
       "      <td>-4.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.64000</td>\n",
       "      <td>1.257400</td>\n",
       "      <td>-0.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.03850</td>\n",
       "      <td>1.422950</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.59700</td>\n",
       "      <td>1.641675</td>\n",
       "      <td>0.596750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.73300</td>\n",
       "      <td>3.152470</td>\n",
       "      <td>5.733000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
       "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \n",
       "mean   2003.016000     0.003834     0.003919     0.001716     0.001636   \n",
       "std       1.409018     1.136299     1.136280     1.138703     1.138774   \n",
       "min    2001.000000    -4.922000    -4.922000    -4.922000    -4.922000   \n",
       "25%    2002.000000    -0.639500    -0.639500    -0.640000    -0.640000   \n",
       "50%    2003.000000     0.039000     0.039000     0.038500     0.038500   \n",
       "75%    2004.000000     0.596750     0.596750     0.596750     0.596750   \n",
       "max    2005.000000     5.733000     5.733000     5.733000     5.733000   \n",
       "\n",
       "             Lag5       Volume        Today  \n",
       "count  1250.00000  1250.000000  1250.000000  \n",
       "mean      0.00561     1.478305     0.003138  \n",
       "std       1.14755     0.360357     1.136334  \n",
       "min      -4.92200     0.356070    -4.922000  \n",
       "25%      -0.64000     1.257400    -0.639500  \n",
       "50%       0.03850     1.422950     0.038500  \n",
       "75%       0.59700     1.641675     0.596750  \n",
       "max       5.73300     3.152470     5.733000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看数据的整体情况\n",
    "smarket.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看前面几行\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据类型换回 ndarray\n",
    "## 这里我们不考虑 Year 这个特征，因为它的数量级跟其他特征差太多了\n",
    "X = np.array(smarket.iloc[:,1:7])\n",
    "y = np.array(smarket['Direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250L, 6L)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的， sklearn 提供了直接调用 Logistic Regression 的函数 LogisticRegression()，使用方法同其他的机器学习函数一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error= 0.4752\n"
     ]
    }
   ],
   "source": [
    "## calculate training error\n",
    "print 'training error= %.4f' % (1 - np.mean(y_pred == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Up' 'Down' 'Down' 'Up' 'Up' 'Up' 'Down' 'Up' 'Up' 'Down']\n"
     ]
    }
   ],
   "source": [
    "print y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看看 y_pred 的结果同样是两类，那我们要怎么看每个样本预测的概率呢？可以使用 predict_proba 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predProbs = logit.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49224404, 0.50775596],\n",
       "       [0.51791235, 0.48208765],\n",
       "       [0.51852092, 0.48147908],\n",
       "       [0.48438969, 0.51561031],\n",
       "       [0.48865013, 0.51134987],\n",
       "       [0.49273069, 0.50726931],\n",
       "       [0.50711612, 0.49288388],\n",
       "       [0.49058882, 0.50941118],\n",
       "       [0.48177107, 0.51822893],\n",
       "       [0.51055965, 0.48944035]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predProbs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看前10个样本的预测结果，左边一列代表分类结果为 Down 的概率，右边一列代表分类结果为 Up 的概率。\n",
    "不过看这个举棋不定的样子，大概就跟瞎猜差不多。\n",
    "\n",
    "炒股有风险，炒股需谨慎。\n",
    "拿来练练手还是可以的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以用 statsmodel 中的函数来做逻辑回归的同时筛选特征，做法有点类似于前面的线性回归。但是我们这里用更 formula 的方式来表示，这样看起来更科学一些。\n",
    "首先导入statsmodels.formula.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后用glm函数来计算。glm=Generalize Linear Model 广义线性模型。当family=Binomial的时候就是用逻辑回归做二元分类。在 formula 部分我们指定需要预测的 column name 和 成为特征的 column name, 表现为线性求和的方式。对应我们的线性模型。在 data 的部分制定数据集就可以了。是不是很方便！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_sm = smf.glm(formula='Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume', data=smarket,\n",
    "                  family=sm.families.Binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit_sm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>  <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                           <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1243</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                 <td>Binomial</td>               <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                  <td>logit</td>                <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                         <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -863.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                     <td>Fri, 04 May 2018</td>           <th>  Deviance:          </th> <td>  1727.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                         <td>15:30:22</td>               <th>  Pearson chi2:      </th> <td>1.25e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                   <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1260</td> <td>    0.241</td> <td>    0.523</td> <td> 0.601</td> <td>   -0.346</td> <td>    0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0731</td> <td>    0.050</td> <td>    1.457</td> <td> 0.145</td> <td>   -0.025</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>    0.0423</td> <td>    0.050</td> <td>    0.845</td> <td> 0.398</td> <td>   -0.056</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag3</th>      <td>   -0.0111</td> <td>    0.050</td> <td>   -0.222</td> <td> 0.824</td> <td>   -0.109</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag4</th>      <td>   -0.0094</td> <td>    0.050</td> <td>   -0.187</td> <td> 0.851</td> <td>   -0.107</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag5</th>      <td>   -0.0103</td> <td>    0.050</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.107</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Volume</th>    <td>   -0.1354</td> <td>    0.158</td> <td>   -0.855</td> <td> 0.392</td> <td>   -0.446</td> <td>    0.175</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
       "Model:                                              GLM   Df Residuals:                     1243\n",
       "Model Family:                                  Binomial   Df Model:                            6\n",
       "Link Function:                                    logit   Scale:                             1.0\n",
       "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
       "Date:                                  Fri, 04 May 2018   Deviance:                       1727.6\n",
       "Time:                                          15:30:22   Pearson chi2:                 1.25e+03\n",
       "No. Iterations:                                       4                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
       "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
       "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
       "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
       "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
       "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
       "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = results.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = np.array(['Down']*len(y))\n",
    "y_pred_class[y_pred < 0.5] = 'Up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error=0.4784\n"
     ]
    }
   ],
   "source": [
    "print 'training error=%.4f' % (1 - np.mean(y_pred_class == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个错误率，也跟瞎猜差不多。但是我们注意到在Lag1和Lag2这两个特征的P值相对于其它特征来说还是比较小的，假如我们把别的都踢掉会怎么样呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_sm_less = smf.glm(formula='Direction~Lag1+Lag2', data=smarket,\n",
    "                  family=sm.families.Binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_less = logit_sm_less.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>  <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                           <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1247</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                 <td>Binomial</td>               <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                  <td>logit</td>                <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                         <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -864.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                     <td>Fri, 04 May 2018</td>           <th>  Deviance:          </th> <td>  1728.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                         <td>15:30:37</td>               <th>  Pearson chi2:      </th> <td>1.25e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                   <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0742</td> <td>    0.057</td> <td>   -1.310</td> <td> 0.190</td> <td>   -0.185</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0715</td> <td>    0.050</td> <td>    1.427</td> <td> 0.153</td> <td>   -0.027</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>    0.0445</td> <td>    0.050</td> <td>    0.890</td> <td> 0.374</td> <td>   -0.054</td> <td>    0.142</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
       "Model:                                              GLM   Df Residuals:                     1247\n",
       "Model Family:                                  Binomial   Df Model:                            2\n",
       "Link Function:                                    logit   Scale:                             1.0\n",
       "Method:                                            IRLS   Log-Likelihood:                -864.20\n",
       "Date:                                  Fri, 04 May 2018   Deviance:                       1728.4\n",
       "Time:                                          15:30:37   Pearson chi2:                 1.25e+03\n",
       "No. Iterations:                                       4                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0742      0.057     -1.310      0.190      -0.185       0.037\n",
       "Lag1           0.0715      0.050      1.427      0.153      -0.027       0.170\n",
       "Lag2           0.0445      0.050      0.890      0.374      -0.054       0.142\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_less.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error=0.4720\n"
     ]
    }
   ],
   "source": [
    "y_pred = results_less.predict()\n",
    "y_pred_class = np.array(['Down']*len(y))\n",
    "y_pred_class[y_pred < 0.5] = 'Up'\n",
    "print 'training error=%.4f' % (1 - np.mean(y_pred_class == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个结果看起来也就好了一点点点吧……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：以2005年之前的数据为训练集，2005年的数据为测试集，计算logistic regression在测试集上的testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
